library(tidyverse)
?read.csbv
?read.csv
getwd()
?mutate
??mutate
?tidyr::mutate
?tidyr:mutate
?mutate
??mutate
packageurl <- "https://cran.r-project.org/src/contrib/Archive/sparcl/sparcl_1.0.3.tar.gz"
install.packages(packageurl, contriburl=NULL, type="source")
library("sparcl")
setRepositories()
library("devtools")
install.packages("devtools")
library("devtools")
install_version("sparcl", "1.0.3")
install_version("sparcl", "1.0")
?sparcl
??sparcl
library(remotes)
install.packages("remotes")
install_version("sparcl", "1.0.3")
install.packages('R Markdown')
install.packages('markdown')
runApp(exercise6)
shiny::runApp('Desktop/UPM/big data/shiny/bd2018_2019/exercise6')
runUrl('https://github.com/Matthew-Ye/exercise6')
runUrl('https://github.com/Matthew-Ye/exercise6/archive/master.tar.gz')
runGitHub( "exercise6", "Matthew-Ye")
runGist("0f1582019873bcd70d79dd90e622f96c")
runGist("0f1582019873bcd70d79dd90e622f96c")
?na.omit
is.finite
?is.finite
?rowSums
library(shiny); runApp('Desktop/UPM/big data/usa/usaa2(1).R')
barchart_plot <- lapply(relevant_features, function(x) {
wgd <- CrossTable(mushrooms[,x], mushrooms$class, prop.chisq=F)
barchart(wgd$prop.row, stack=F, auto.key=list(rectangles = TRUE, space = "top", title = x))
})
names(barchart_plot) <- relevant_features
install.packages("rJava")
library(rJava)
dyn.load('/Library/Java/JavaVirtualMachines/jdk1.8.0_162.jdk/Contents/Home/jre/lib/server/libjvm.dylib')
dyn.load()
dyn.load('/Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home/jre/lib/server/libjvm.dylib')
dyn.load('/Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home/jre/lib/server/libjvm.dylib')
dyn.load('/Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home/lib/server/libjvm.dylib')
library(rJava)
dyn.load('/Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home/lib/server/libjvm.dylib')
dyn.load()
require(rJava)
dyn.load('/Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home/lib/server/libjvm.dylib')
dyn.load('/Library/Java/JavaVirtualMachines/jdk1.8.0_192.jdk/Contents/Home/lib/server/libjvm.dylib')
dyn.load('/Library/Java/JavaVirtualMachines/jdk1.8.0_192.jdk/Contents/Home/jre/lib/server/libjvm.dylib')
require(rJava)
library(rJava)
library("rJava")
dyn.load('/Library/Java/JavaVirtualMachines/jdk1.8.0_192.jdk/Contents/Home/jre/lib/server/libjvm.dylib')
library(rJava)
dyn.load('/Library/Java/JavaVirtualMachines/jdk1.8.0_192.jdk/Contents/Home/jre/lib/server/libjvm.dylib')
library(rJava)
dyn.load(paste0(system2('/usr/libexec/java_home', stdout = TRUE), '/jre/lib/server/libjvm.dylib'))
library(rJava)
dyn.load(paste0(system2('/usr/libexec/java_home', stdout = TRUE), '/jre/lib/server/libjvm.dylib'))
dyn.load('/Library/Java/JavaVirtualMachines/jdk1.8.0_192.jdk/Contents/Home/jre/lib/server/libjvm.dylib')
library(rJava)
library(shiny); runApp('Desktop/UPM/big data/usa/usaa2(1).R')
runApp('Desktop/UPM/big data/usa/usaa0.R')
runApp('Desktop/UPM/big data/usa/usaa1.R')
runApp('Desktop/UPM/big data/usa/usaa3.R')
library(shiny); runApp('Desktop/UPM/big data/usa/usaa4.R')
install.packages("highcharter")
runApp('Desktop/UPM/big data/usa/usaa4.R')
usa <- read.csv("usa.csv", stringsAsFactors = FALSE)
runApp('Desktop/UPM/big data/usa/usaa4.R')
runApp('Desktop/UPM/big data/usa/usaa4.R')
runApp('Desktop/UPM/big data/usa/usaa4.R')
i
i
i
i
i
library(shiny)
library(maps)
library(googleVis)
library(ggplot2)
library(gridExtra)
library(cowplot)
library(splines2)
library(MASS)
library(mclust)
library(Gmedian)
library(shinydashboard)
library(cluster)
library(highcharter)
runApp('Desktop/UPM/big data/usa/usaa4.R')
runApp('Desktop/UPM/big data/usa/usaa4.R')
library(dplyr)
runApp('Desktop/UPM/big data/usa/usaa4.R')
?usgeojson
runApp('Desktop/UPM/big data/usa/usaa4.R')
runApp('Desktop/UPM/big data/usa/usaa4.R')
runApp('Desktop/UPM/big data/usa/usaa4.R')
runApp('Desktop/UPM/big data/usa/usaa4.R')
runApp('Desktop/UPM/big data/usa/usaa4.R')
runApp('Desktop/UPM/big data/usa/usaa3.R')
runApp('Desktop/UPM/big data/usa/usaa3.R')
runApp('Desktop/UPM/big data/usa/usaa3.R')
runApp('Desktop/UPM/big data/usa/usaa3.R')
runApp('Desktop/UPM/big data/usa/usaa3.R')
library(shiny); runApp('Desktop/UPM/big data/usa/usaa3.R')
library(shiny); runApp('Desktop/UPM/big data/usa/usaa5.R')
runApp('Desktop/UPM/big data/usa/usaa5.R')
runApp('Desktop/UPM/big data/usa/usaa5.R')
runApp('Desktop/UPM/big data/usa/usaa5.R')
runApp('Desktop/UPM/big data/usa/usaa5.R')
runApp('Desktop/UPM/big data/usa/usaa5.R')
runApp('Desktop/UPM/big data/usa/usaa4.R')
runApp('Desktop/UPM/big data/usa/hie.R')
runApp('Desktop/UPM/big data/usa/kmeans.R')
runApp('Desktop/UPM/big data/usa/usaa5.R')
runApp('Desktop/UPM/big data/usa/usaa5.R')
runApp('Desktop/UPM/big data/usa/usaa5.R')
runApp('Desktop/UPM/big data/usa/kmeans.R')
runApp('Desktop/UPM/big data/usa/kmeans.R')
runApp('Desktop/UPM/big data/usa/kmeans.R')
runApp('Desktop/UPM/big data/usa/kmeans.R')
suppressPackageStartupMessages(library(Kmisc))
install.packages("Kmisc")
install.packages("~/Downloads/Kmisc_0.5.0.tar.gz", repos = NULL, type = "source")
suppressPackageStartupMessages(library(Kmisc))
devtools::install_github("kevinushey/Kmisc")
devtools::install_github("kevinushey/Kmisc")
devtools::install_github("kevinushey/Kmisc")
devtools::install_github("kevinushey/Kmisc")
library(readr)
library(sqldf)
library(ggplot2)
setwd('/users/mingjie/desktop/UPM/cognitive systems/mushrooms')
library(readr)
library(sqldf)
library(ggplot2)
library(caret)
library(randomForest)
library(caTools)   #<- For stratified split
mushrooms <- read.csv("test_data.csv",header=TRUE)
setwd('/users/mingjie/desktop/UPM/cognitive systems/mushrooms/mushroom')
library(readr)
library(sqldf)
library(ggplot2)
library(caret)
library(randomForest)
library(caTools)   #<- For stratified split
mushrooms <- read.csv("test_data.csv",header=TRUE)
dim(mushrooms)
str(mushrooms)
head(mushrooms)
summary(mushrooms)
#tables
mush_features <- colnames(mushrooms)[-1]
tables <- lapply(mush_features, function(x) {table(mushrooms$class, mushrooms[,x])})
names(tables) <- mush_features
#tables
mush_features <- colnames(mushrooms)[-1]
tables <- lapply(mush_features, function(x) {table(mushrooms$class, mushrooms[,x])})
#tables
mush_features <- colnames(mushrooms)[-1]
tables <- lapply(mush_features, function(x) {table(mushrooms$class, mushrooms[,x])})
names(tables) <- mush_features
mushrooms <- read.csv("mushrooms.csv",header=TRUE)
dim(mushrooms)
str(mushrooms)
head(mushrooms)
summary(mushrooms)
#tables
mush_features <- colnames(mushrooms)[-1]
tables <- lapply(mush_features, function(x) {table(mushrooms$class, mushrooms[,x])})
names(tables) <- mush_features
print(tables)
#correlation analysis
chisq_test_res = list()
for (i in 2:length(colnames(mushrooms))) {
fname = colnames(mushrooms)[i]
res = chisq.test(mushrooms[,i], mushrooms[,"class"], simulate.p.value = TRUE)
res$data.name = paste(fname, "class", sep= " and ")
chisq_test_res[[fname]] = res
}
chisq_test_res
#perform query on thedataset
query_1 <- sqldf("select class,population from mushrooms where habitat =='d'")
table(query_1)
query_2 <- sqldf("select class,odor from mushrooms where bruises =='t'")
table(query_2)
#Distribution of variables,barplot,capcolor
ggplot(data=mushrooms, aes(x = cap.color, fill = class)) + geom_bar()  + scale_fill_manual("legend", values = c("e" = "pink", "p" = "red")) + ggtitle("")
#Distribution of variables,pieplot,capcolor
data1<-data.frame(table(mushrooms$cap.color))
data1 = data1[order(data1$Freq, decreasing = TRUE),]
myLabel = as.vector(data1$Var1)
myLabel = paste(myLabel, "(", round(data1$Freq / sum(data1$Freq) * 100, 2), "%)", sep = "")
ggplot(data1, aes(x = "", y = Freq, fill = Var1)) + geom_bar(stat = "identity", width = 1) +scale_fill_discrete(breaks = data1$Var1, labels = myLabel)+coord_polar(theta = "y") + labs(x = "", y = "", title = "") + theme(axis.ticks = element_blank()) + theme(axis.text = element_blank())+ theme(legend.title = element_blank())+ ggtitle("capcolor")
#Distribution of variables,barplot,capshape
ggplot(data=mushrooms, aes(x = cap.shape, fill = class)) + geom_bar()  + scale_fill_manual("legend", values = c("e" = "pink", "p" = "red")) + ggtitle("")
#Distribution of variables,pieplot,capshape
data2<-data.frame(table(mushrooms$cap.shape))
myLabel2 = as.vector(data2$Var1)
myLabel2 = paste(myLabel2, "(", round(data2$Freq / sum(data2$Freq) * 100, 2), "%)", sep = "")
ggplot(data2, aes(x = "", y = Freq, fill = Var1)) + geom_bar(stat = "identity", width = 1) +scale_fill_discrete(breaks = data2$Var1, labels = myLabel2)+coord_polar(theta = "y") + labs(x = "", y = "", title = "") + theme(axis.ticks = element_blank()) + theme(axis.text = element_blank())+ theme(legend.title = element_blank()) + ggtitle("capshape")
train01 <- mushrooms
# Calculate number of class for each variable
z<-cbind.data.frame(Var=names(train01), Total_Class=sapply(train01,function(x){as.numeric(length(levels(x)))}))
print(z)
# create 70:30 stratified split using caret between Train and Test.
set.seed(101)
sample = sample.split(train01$class, SplitRatio = .7)
x_train = subset(train01, sample == TRUE)
x_test = subset(train01, sample == FALSE)
y_train<-x_train$class
y_test <- x_test$class
x_train$class<-NULL
x_test$class<-NULL
# Create a stratified sample for repeated cv
cv.10.folds<-createMultiFolds(y_train,k=10,times=2)
# create a control object for repeated cv in caret
ctrl.1<-trainControl(method="repeatedcv",number=10,repeats=2,index=cv.10.folds)
# Model 1: random forest
rf.1.cv<-train(x_train,y_train,method="rf",trControl=ctrl.1,tuneLength=3)
plot(varImp(rf.1.cv),main="Random Forest - Variable Importance Plot")
# predict on test set and see the confusion matrix
y_predicted<-predict(rf.1.cv,x_test)
df1<-data.frame(Orig=y_test,Pred=y_predicted)
confusionMatrix(table(df1$Orig,df1$Pred))
# Model 2: RPART model
rpart <-train(x=x_train,y=y_train,method="rpart",trControl=ctrl.1,tuneLength=3)
plot(varImp(rpart),main="RPART - Variable Importance Plot")
rpart.plot(rpart$finalModel) #<- creates the decision tree with better formatting
rpart.plot(rpart$finalModel) #<- creates the decision tree with better formatting
library(rpart.plot)
library(rpart.plot)
library(rpart.plot)
# Model 2: RPART model
rpart <-train(x=x_train,y=y_train,method="rpart",trControl=ctrl.1,tuneLength=3)
plot(varImp(rpart),main="RPART - Variable Importance Plot")
rpart.plot(rpart$finalModel) #<- creates the decision tree with better formatting
y2_predicted<-predict(rpart,x_test)
df2<-data.frame(Orig=y_test,Pred=y2_predicted)
confusionMatrix(table(df2$Orig,df2$Pred))  #<-100% accuracy
# Model 3: bayesglm model
bayesglm <- train(x_train, y_train, method = "bayesglm", trControl = ctrl.1, tuneLength=3)
plot(varImp(bayesglm), main = "bayesglm - Variable Importance plot")
y3_predicted <- predict(bayesglm, x_test)
df3 <- data.frame (Original = y_test, Predicted = y3_predicted)
confusionMatrix(table(df3$Original, df3$Predicted))
# Model 4: C5.0
c50_fit <- train(x_train, y_train, method ="C5.0Rules", trControl = ctrl.1, tuneLength=3)
plot(varImp(c50_fit), main = "c50_fit - Variable Importance plot")
y4_predicted <- predict(c50_fit, x_test)
df4 <- data.frame (Original = y_test, Predicted = y4_predicted)
confusionMatrix(table(df4$Original, df4$Predicted))
# Model 5: Conditional Tree
ctree <- train(x_train, y_train, method ="ctree", trControl = ctrl.1, tuneLength=3)
plot(varImp(ctree), main = "Conditional Tree - Variable Importance plot")
y5_predicted <- predict(ctree, x_test)
df5 <- data.frame (Original = y_test, Predicted = y5_predicted)
confusionMatrix(table(df5$Original, df5$Predicted))
# Comparing Models
results <- resamples(list(RF=rf.1.cv, RPART=rpart, BAYESGLM=bayesglm, C5.0Rules=c50_fit, CTREE=ctree))
bwplot(results)
#save x_test to CSV file
write.csv(x_test, 'test_data.csv', row.names = FALSE)
#save the model
save(rf.1.cv , file = 'RandomForest.rda')
#save the model
save(rf.1.cv , file = 'RandomForest.rda')
library(shiny); runApp('mushdeploy.R')
